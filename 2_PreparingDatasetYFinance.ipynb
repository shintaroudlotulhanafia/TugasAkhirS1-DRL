{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_PreparingDatasetYFinance.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyML3WjUxTasvGgY9NHph43R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shintaroudlotulhanafia/TugasAkhirS1-DRL/blob/main/2_PreparingDatasetYFinance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After getting daily data of each stock from Yahoo Finance Scrapper, here is the program to merge each file and make the data in the format that is needed."
      ],
      "metadata": {
        "id": "E12BkHxHaC8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCjTyktTZz95",
        "outputId": "41f10ee9-30d1-4110-e1b8-71c3ea0a5ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# connecting gdrive into the google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing files on a folder\n",
        "\n",
        "import os\n",
        "\n",
        "path = '/content/gdrive/MyDrive/TugasAkhirS1-DRL/1YahooFinanceScrapper/1.1.DataPerStocks'\n",
        "files = os.listdir(path)\n",
        "\n",
        "for f in files:\n",
        "\tprint(f)"
      ],
      "metadata": {
        "id": "5401njCza3jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "import pandas as pd\n",
        "\n",
        "file_count = len(files)\n",
        "\n",
        "# create empty list\n",
        "dataframes_list = []\n",
        "\n",
        "# append datasets to the list\n",
        "for i in range(file_count):\n",
        "\ttemp_df = pd.read_csv(path+\"/\"+files[i])\n",
        "\tdataframes_list.append(temp_df)\n",
        "\t\n",
        "# display datasets\n",
        "for dataset in dataframes_list:\n",
        "\tdisplay(dataset)"
      ],
      "metadata": {
        "id": "m_ueW6-vbS4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "WQYFPtakbXfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Date format\n",
        "for df in dataframes_list:\n",
        "  df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "  df['Date'] = df['Date'].dt.strftime('%Y%m%d')\n",
        "\n",
        "for df in dataframes_list:\n",
        "  display(df)"
      ],
      "metadata": {
        "id": "vX3784tnbZWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Column of tic\n",
        "\n",
        "i=0\n",
        "ticList = []\n",
        "for f in files:\n",
        "  ticName = f[:4]\n",
        "  ticList.append(ticName)\n",
        "\n",
        "print(ticList)\n",
        "\n",
        "j=0\n",
        "for df in dataframes_list:\n",
        "  ticValue = ticList[j]\n",
        "  df.insert(1, \"Ticker\", ticValue, True)\n",
        "  j=j+1\n",
        "  display(df)"
      ],
      "metadata": {
        "id": "eWmtinz_bdfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change order of the columns\n",
        "newHeaderDataframesList = []\n",
        "\n",
        "for df in dataframes_list:\n",
        "  df = df[['Date', 'Ticker', 'Adj Close', 'Open', 'High', 'Low', 'Volume']]\n",
        "  newHeaderDataframesList.append(df)\n",
        "  display(df)"
      ],
      "metadata": {
        "id": "aoEa4aUibgqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the Dataframes\n",
        "mergedDataframe = pd.concat(newHeaderDataframesList,ignore_index=True)\n",
        "mergedDataframe.columns = ['datadate', 'tic', 'adjcp', 'open', 'high', 'low', 'volume']\n",
        "display(mergedDataframe)"
      ],
      "metadata": {
        "id": "hMLTHarFbi6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataframe as csv\n",
        "dataset = mergedDataframe.to_csv(\"/content/gdrive/MyDrive/TugasAkhirS1-DRL/1YahooFinanceScrapper/1.2.MergedDataset\")"
      ],
      "metadata": {
        "id": "Bh0BBY6WblLu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}