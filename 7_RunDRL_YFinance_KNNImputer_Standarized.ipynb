{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_RunDRL_YFinance_KNNImputer_Standarized.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1djjvHvZJM_77nVJA1nTL-Gg5Po8rtl9j",
      "authorship_tag": "ABX9TyNM1/SBuPBNdUnIKYBP4Wsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shintaroudlotulhanafia/TugasAkhirS1-DRL/blob/main/7_RunDRL_YFinance_KNNImputer_Standarized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Yahoo Finance dataset. The two NaN rows already handled by KNN Imputer. All the value of numeric features already standarized. Here is the file: 0(YFinance_JIIDataset_2009_2021_Original_WithNan).csv."
      ],
      "metadata": {
        "id": "oPmWFtRI2zsP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ3k8dataVuZ",
        "outputId": "fa2cf951-2420-48a0-a4c4-bbd9ccf2720a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/TugasAkhirS1-DRL/3DRLForAutomatedStockTrading/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IepWzNdUbHvM",
        "outputId": "756d3af7-ce03-4c2d-b50a-e4c33dd546ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TugasAkhirS1-DRL/3DRLForAutomatedStockTrading/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3LNvUkWbgbn",
        "outputId": "61bec843-0a7b-4b46-9ea3-72c9dbc7465c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (20.14.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (0.3.4)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.7.1)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (2.5.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.11.4)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!virtualenv -p python3 venv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqfxMcokbjEg",
        "outputId": "d0253252-c3e8-4b73-8de0-9e76ecd9791e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.7.13.final.0-64 in 6434ms\n",
            "  creator CPython3Posix(dest=/content/drive/MyDrive/TugasAkhirS1-DRL/3DRLForAutomatedStockTrading/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020-master/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==22.1.2, setuptools==62.3.4, wheel==0.37.1\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source venv/bin/activate"
      ],
      "metadata": {
        "id": "cFOhOe00bksK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdBZ3WsHbmSh",
        "outputId": "7a1d94ca-fd05-42c4-f8ee-2162ef05316c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.16.4)\n",
            "Requirement already satisfied: pandas==1.0.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn==0.21.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: gym==0.15.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.15.3)\n",
            "Requirement already satisfied: stable-baselines[mpi] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.10.2)\n",
            "Requirement already satisfied: tensorflow==1.15.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.15.4)\n",
            "Requirement already satisfied: joblib==0.15.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.15.1)\n",
            "Requirement already satisfied: matplotlib==3.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (3.2.1)\n",
            "Requirement already satisfied: pytest<6.0.0,>=5.3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (5.4.3)\n",
            "Requirement already satisfied: setuptools<42.0.0,>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (41.6.0)\n",
            "Requirement already satisfied: wheel<0.34.0,>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.33.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.0->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.46.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.15.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (1.4.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (0.2.5)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (21.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (1.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (21.3)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (0.13.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (4.11.4)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (8.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (3.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.3->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements.txt (line 8)) (3.3.7)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]->-r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (0.2.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines[mpi]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwTBMHlAboUN",
        "outputId": "a0fea193-6901-43e8-922a-97621e3575ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable-baselines[mpi] in /usr/local/lib/python3.7/dist-packages (2.10.2)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (0.15.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (0.15.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]) (3.1.3)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]) (2022.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_DRL.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG3ZgCmubvsn",
        "outputId": "d36ee289-5f42-480d-a370-92328f9603ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n",
            "   datadate  ... turbulence\n",
            "0  20090102  ...        0.0\n",
            "1  20090102  ...        0.0\n",
            "2  20090102  ...        0.0\n",
            "3  20090102  ...        0.0\n",
            "4  20090102  ...        0.0\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "1053360\n",
            "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n",
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20151002\n",
            "======A2C Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:194: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Training time (A2C):  1.1746498664220175  minutes\n",
            "======A2C Validation from:  20151002 to  20160104\n",
            "A2C Sharpe Ratio:  0.022386522283630843\n",
            "======PPO Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "Training time (PPO):  4.043576077620188  minutes\n",
            "======PPO Validation from:  20151002 to  20160104\n",
            "PPO Sharpe Ratio:  0.09555926361212813\n",
            "======DDPG Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ddpg/policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ddpg/ddpg.py:94: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ddpg/ddpg.py:444: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:432: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "Training time (DDPG):  0.7055298884709676  minutes\n",
            "======DDPG Validation from:  20151002 to  20160104\n",
            "======Trading from:  20160104 to  20160405\n",
            "previous_total_asset:1000000\n",
            "end_total_asset:1102723.001307214\n",
            "total_reward:102723.00130721391\n",
            "total_cost:  3527.690121496824\n",
            "total trades:  1210\n",
            "Sharpe:  0.3406230413226619\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20160104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.1840095241864523  minutes\n",
            "======A2C Validation from:  20160104 to  20160405\n",
            "A2C Sharpe Ratio:  0.09250376401953414\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.0887414415677386  minutes\n",
            "======PPO Validation from:  20160104 to  20160405\n",
            "PPO Sharpe Ratio:  0.056458302490042245\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7202523668607076  minutes\n",
            "======DDPG Validation from:  20160104 to  20160405\n",
            "======Trading from:  20160405 to  20160705\n",
            "previous_total_asset:1102723.001307214\n",
            "end_total_asset:1118493.264614284\n",
            "total_reward:15770.263307070127\n",
            "total_cost:  1369.3323388477208\n",
            "total trades:  914\n",
            "Sharpe:  0.06750272223865593\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20160405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2023311853408813  minutes\n",
            "======A2C Validation from:  20160405 to  20160705\n",
            "A2C Sharpe Ratio:  0.0007636333815335106\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.053021911780039  minutes\n",
            "======PPO Validation from:  20160405 to  20160705\n",
            "PPO Sharpe Ratio:  0.028514600900849188\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7174532373746236  minutes\n",
            "======DDPG Validation from:  20160405 to  20160705\n",
            "======Trading from:  20160705 to  20161003\n",
            "previous_total_asset:1118493.264614284\n",
            "end_total_asset:1127618.1310705757\n",
            "total_reward:9124.866456291638\n",
            "total_cost:  1266.8775173006275\n",
            "total trades:  886\n",
            "Sharpe:  0.042982700952208346\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20160705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.181873587767283  minutes\n",
            "======A2C Validation from:  20160705 to  20161003\n",
            "A2C Sharpe Ratio:  -0.04080349540213366\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.137152512868245  minutes\n",
            "======PPO Validation from:  20160705 to  20161003\n",
            "PPO Sharpe Ratio:  0.0057076587078184185\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7136589686075846  minutes\n",
            "======DDPG Validation from:  20160705 to  20161003\n",
            "======Trading from:  20161003 to  20170103\n",
            "previous_total_asset:1127618.1310705757\n",
            "end_total_asset:1143624.31475379\n",
            "total_reward:16006.183683214244\n",
            "total_cost:  1100.2035290081544\n",
            "total trades:  992\n",
            "Sharpe:  0.08067962799303285\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20161003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.1793761054674785  minutes\n",
            "======A2C Validation from:  20161003 to  20170103\n",
            "A2C Sharpe Ratio:  0.2619821351892126\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.087504915396372  minutes\n",
            "======PPO Validation from:  20161003 to  20170103\n",
            "PPO Sharpe Ratio:  0.47278768787697323\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.703415310382843  minutes\n",
            "======DDPG Validation from:  20161003 to  20170103\n",
            "======Trading from:  20170103 to  20170404\n",
            "previous_total_asset:1143624.31475379\n",
            "end_total_asset:1175391.8394225573\n",
            "total_reward:31767.52466876735\n",
            "total_cost:  2883.973109204682\n",
            "total trades:  1293\n",
            "Sharpe:  0.21439777507799\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20170103\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.1774068554242452  minutes\n",
            "======A2C Validation from:  20170103 to  20170404\n",
            "A2C Sharpe Ratio:  0.34053618998554636\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.049225799242655  minutes\n",
            "======PPO Validation from:  20170103 to  20170404\n",
            "PPO Sharpe Ratio:  0.030675209017891652\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7288839777310689  minutes\n",
            "======DDPG Validation from:  20170103 to  20170404\n",
            "======Trading from:  20170404 to  20170705\n",
            "previous_total_asset:1175391.8394225573\n",
            "end_total_asset:1202454.0618540996\n",
            "total_reward:27062.222431542352\n",
            "total_cost:  5661.398087993689\n",
            "total trades:  1227\n",
            "Sharpe:  0.21555356543006501\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20170404\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.189210061232249  minutes\n",
            "======A2C Validation from:  20170404 to  20170705\n",
            "A2C Sharpe Ratio:  0.2607432284882908\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.073038526376089  minutes\n",
            "======PPO Validation from:  20170404 to  20170705\n",
            "PPO Sharpe Ratio:  0.2098262698545758\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7133518536885579  minutes\n",
            "======DDPG Validation from:  20170404 to  20170705\n",
            "======Trading from:  20170705 to  20171003\n",
            "previous_total_asset:1202454.0618540996\n",
            "end_total_asset:1250499.2046311174\n",
            "total_reward:48045.14277701778\n",
            "total_cost:  8859.161445161475\n",
            "total trades:  1534\n",
            "Sharpe:  0.3350032534944129\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20170705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.1797521591186524  minutes\n",
            "======A2C Validation from:  20170705 to  20171003\n",
            "A2C Sharpe Ratio:  0.14773901296109737\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.181172839800516  minutes\n",
            "======PPO Validation from:  20170705 to  20171003\n",
            "PPO Sharpe Ratio:  0.4221420689366017\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7217428247133891  minutes\n",
            "======DDPG Validation from:  20170705 to  20171003\n",
            "======Trading from:  20171003 to  20180103\n",
            "previous_total_asset:1250499.2046311174\n",
            "end_total_asset:1415323.4076461757\n",
            "total_reward:164824.2030150583\n",
            "total_cost:  6783.585726305461\n",
            "total trades:  1477\n",
            "Sharpe:  0.7995957924989198\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20171003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2152791500091553  minutes\n",
            "======A2C Validation from:  20171003 to  20180103\n",
            "A2C Sharpe Ratio:  0.48576479226949676\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.1778640985488895  minutes\n",
            "======PPO Validation from:  20171003 to  20180103\n",
            "PPO Sharpe Ratio:  0.44530995009829016\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7193414131800334  minutes\n",
            "======DDPG Validation from:  20171003 to  20180103\n",
            "======Trading from:  20180103 to  20180405\n",
            "previous_total_asset:1415323.4076461757\n",
            "end_total_asset:1442382.1221218612\n",
            "total_reward:27058.714475685498\n",
            "total_cost:  2526.1125191944993\n",
            "total trades:  383\n",
            "Sharpe:  0.16421156940574244\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20180103\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2141180475552877  minutes\n",
            "======A2C Validation from:  20180103 to  20180405\n",
            "A2C Sharpe Ratio:  -0.04639649460447969\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.192951889832814  minutes\n",
            "======PPO Validation from:  20180103 to  20180405\n",
            "PPO Sharpe Ratio:  -0.051846682071743456\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7261603434880575  minutes\n",
            "======DDPG Validation from:  20180103 to  20180405\n",
            "======Trading from:  20180405 to  20180705\n",
            "previous_total_asset:1442382.1221218612\n",
            "end_total_asset:1429179.9840989148\n",
            "total_reward:-13202.138022946427\n",
            "total_cost:  3715.0784304736817\n",
            "total trades:  744\n",
            "Sharpe:  -0.045468803408727686\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20180405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2243776003519693  minutes\n",
            "======A2C Validation from:  20180405 to  20180705\n",
            "A2C Sharpe Ratio:  -0.14349702847807178\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.18637307882309  minutes\n",
            "======PPO Validation from:  20180405 to  20180705\n",
            "PPO Sharpe Ratio:  -0.05825955345277622\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7154342452685039  minutes\n",
            "======DDPG Validation from:  20180405 to  20180705\n",
            "======Trading from:  20180705 to  20181003\n",
            "previous_total_asset:1429179.9840989148\n",
            "end_total_asset:1438683.8343215468\n",
            "total_reward:9503.850222632056\n",
            "total_cost:  6379.730749693051\n",
            "total trades:  951\n",
            "Sharpe:  0.0750273659671832\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20180705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2055739124615987  minutes\n",
            "======A2C Validation from:  20180705 to  20181003\n",
            "A2C Sharpe Ratio:  0.274186404573837\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.176907531420389  minutes\n",
            "======PPO Validation from:  20180705 to  20181003\n",
            "PPO Sharpe Ratio:  0.10097497918497757\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7244141896565756  minutes\n",
            "======DDPG Validation from:  20180705 to  20181003\n",
            "======Trading from:  20181003 to  20190104\n",
            "previous_total_asset:1438683.8343215468\n",
            "end_total_asset:1446193.5351546519\n",
            "total_reward:7509.7008331050165\n",
            "total_cost:  820.1482509209169\n",
            "total trades:  162\n",
            "Sharpe:  0.2322078270517239\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20181003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2180740674336752  minutes\n",
            "======A2C Validation from:  20181003 to  20190104\n",
            "A2C Sharpe Ratio:  -0.39320954736559477\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.2592196305592855  minutes\n",
            "======PPO Validation from:  20181003 to  20190104\n",
            "PPO Sharpe Ratio:  -0.334664635852111\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7350350300470988  minutes\n",
            "======DDPG Validation from:  20181003 to  20190104\n",
            "======Trading from:  20190104 to  20190405\n",
            "previous_total_asset:1446193.5351546519\n",
            "end_total_asset:1477966.531480298\n",
            "total_reward:31772.99632564606\n",
            "total_cost:  8733.070381751755\n",
            "total trades:  1444\n",
            "Sharpe:  0.10850082941265698\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20190104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2471962332725526  minutes\n",
            "======A2C Validation from:  20190104 to  20190405\n",
            "A2C Sharpe Ratio:  0.16112065442197876\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.263502244154612  minutes\n",
            "======PPO Validation from:  20190104 to  20190405\n",
            "PPO Sharpe Ratio:  0.09763617166205424\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7293696125348409  minutes\n",
            "======DDPG Validation from:  20190104 to  20190405\n",
            "======Trading from:  20190405 to  20190708\n",
            "previous_total_asset:1477966.531480298\n",
            "end_total_asset:1482403.1306994515\n",
            "total_reward:4436.599219153635\n",
            "total_cost:  1038.7221408539895\n",
            "total trades:  177\n",
            "Sharpe:  0.25983355185630375\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20190405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.193228507041931  minutes\n",
            "======A2C Validation from:  20190405 to  20190708\n",
            "A2C Sharpe Ratio:  0.2598596359613761\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.217552467187246  minutes\n",
            "======PPO Validation from:  20190405 to  20190708\n",
            "PPO Sharpe Ratio:  0.29308692253134583\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7345364729563395  minutes\n",
            "======DDPG Validation from:  20190405 to  20190708\n",
            "======Trading from:  20190708 to  20191004\n",
            "previous_total_asset:1482403.1306994515\n",
            "end_total_asset:1480728.1296318457\n",
            "total_reward:-1675.001067605801\n",
            "total_cost:  2046.1106997907314\n",
            "total trades:  347\n",
            "Sharpe:  -0.041597267735269394\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20190708\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.240492316087087  minutes\n",
            "======A2C Validation from:  20190708 to  20191004\n",
            "A2C Sharpe Ratio:  -0.009185467656948295\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.245488655567169  minutes\n",
            "======PPO Validation from:  20190708 to  20191004\n",
            "PPO Sharpe Ratio:  -0.10650774858112182\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7213910937309265  minutes\n",
            "======DDPG Validation from:  20190708 to  20191004\n",
            "======Trading from:  20191004 to  20200106\n",
            "previous_total_asset:1480728.1296318457\n",
            "end_total_asset:1480060.3084963085\n",
            "total_reward:-667.8211355372332\n",
            "total_cost:  391.86300935867314\n",
            "total trades:  66\n",
            "Sharpe:  -0.09829936965344115\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20191004\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2533895055452982  minutes\n",
            "======A2C Validation from:  20191004 to  20200106\n",
            "A2C Sharpe Ratio:  0.02125542774052873\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.25702348947525  minutes\n",
            "======PPO Validation from:  20191004 to  20200106\n",
            "PPO Sharpe Ratio:  -0.33161778605105036\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7482391953468323  minutes\n",
            "======DDPG Validation from:  20191004 to  20200106\n",
            "======Trading from:  20200106 to  20200406\n",
            "previous_total_asset:1480060.3084963085\n",
            "end_total_asset:1465001.2515384448\n",
            "total_reward:-15059.056957863737\n",
            "total_cost:  907.6663917787514\n",
            "total trades:  176\n",
            "Sharpe:  -0.46073548557297234\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20200106\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.2527808904647828  minutes\n",
            "======A2C Validation from:  20200106 to  20200406\n",
            "A2C Sharpe Ratio:  -0.4491164424310842\n",
            "======PPO Training========\n",
            "Training time (PPO):  4.285834507147471  minutes\n",
            "======PPO Validation from:  20200106 to  20200406\n",
            "PPO Sharpe Ratio:  -0.38379526183561885\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.7263797799746196  minutes\n",
            "======DDPG Validation from:  20200106 to  20200406\n",
            "======Trading from:  20200406 to  20200707\n",
            "previous_total_asset:1465001.2515384448\n",
            "end_total_asset:1469814.1184451128\n",
            "total_reward:4812.8669066680595\n",
            "total_cost:  469.59190709633583\n",
            "total trades:  102\n",
            "Sharpe:  0.263818463297397\n",
            "Ensemble Strategy took:  110.02213909228642  minutes\n",
            "[0eb8d5232b35:01936] *** Process received signal ***\n",
            "[0eb8d5232b35:01936] Signal: Segmentation fault (11)\n",
            "[0eb8d5232b35:01936] Signal code: Address not mapped (1)\n",
            "[0eb8d5232b35:01936] Failing at address: 0x7eff20e9220d\n",
            "[0eb8d5232b35:01936] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7eff23b3a980]\n",
            "[0eb8d5232b35:01936] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7eff23779775]\n",
            "[0eb8d5232b35:01936] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7eff23fe4e44]\n",
            "[0eb8d5232b35:01936] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7eff2377a605]\n",
            "[0eb8d5232b35:01936] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7eff23fe2cb3]\n",
            "[0eb8d5232b35:01936] *** End of error message ***\n"
          ]
        }
      ]
    }
  ]
}